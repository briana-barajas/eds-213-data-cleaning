---
title: "Data Cleaning - Assignment 2"
author: "Briana Barajas"
date: 2024-04-17
format: html
---

## Set-Up

**Github URL:** <https://github.com/briana-barajas/eds-213-data-cleaning>

```{r, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

### Load Libraries

```{r, results='hide'}
# load libraries
library(tidyverse)
library(here)
library(janitor)

# read in data
snowsurvey_raw <- read_csv(here("data", "raw", "ASDN_Snow_survey.csv")) %>% clean_names()
```

### Clean `snow_cover` column

Instead of reading in the processed data, I decided to rewrite the original code for cleaning the `snow_cover` column.

```{r}
snowsurvey_clean <- snowsurvey_raw %>% 
  
  # change select symbols to NA
  mutate(snow_cover = ifelse(snow_cover %in% c(".", "-", "n/a", "unk"), NA, snow_cover)) %>% 
  
  # change values less than 1 to zero
  mutate(snow_cover = ifelse(snow_cover == "<1", 0, snow_cover)) %>% 
  
  # convert snow cover column to numeric
  mutate(snow_cover = as.numeric(snow_cover)) %>% 
  
  # set incorrect percentages to NA
  mutate(snow_cover = ifelse(snow_cover > 100, NA, snow_cover))

```

## Clean `water_cover` column

#### Managing NA Values

I wanted to begin by exploring the values in the `water_cover` column. To avoid having lengthy outputs in the rendered document, I have the exploratory chunk set to `eval = FALSE`. The water cover column had many of the same character strings seen in the snow cover, so I followed the same steps to convert them to NA.

```{r, eval=FALSE}
# check of water cover is correct data type
class(snowsurvey_clean$water_cover)

# check if it has similar characters for NAs as snow cover
snowsurvey_clean %>% 
  filter(water_cover %in% c(".", "-", "n/a", "unk")) %>% 
  View()

# view values for water cover
unique(snowsurvey_clean$water_cover)
```

```{r}
snowsurvey_clean <- snowsurvey_clean %>% 
  
  # convert symbols/text into NAs 
  mutate(water_cover = ifelse(water_cover %in% c(".", "-", "n/a", "unk"), NA, water_cover)) %>% 
  
  # coerce to numeric
  mutate(water_cover = as.numeric(water_cover))
```

#### Checking Percentages

Now that the water cover is numeric, I used the maximum and minimum values to see if the range of values was between 0 and 100%. There was only a single value over 100, so I decided to change it to an NA value.

```{r, eval=FALSE}
# check column type updated
class(snowsurvey_clean$water_cover)

# confirm numeric values are between 0-100
min(snowsurvey_clean$water_cover, na.rm = TRUE)
max(snowsurvey_clean$water_cover, na.rm = TRUE)

# view columns greater than 100
snowsurvey_clean %>% 
  filter(water_cover > 100) %>% 
  head(10)
```

```{r}
snowsurvey_clean <- snowsurvey_clean %>% 
  
  # change values over 100% to NA
  mutate(water_cover = ifelse(water_cover > 100, NA, water_cover))
```

## Clean `land_cover` column

Since the following steps have been the same for the previous columns, I combined them all into one step for land cover. I began by assessing potential NA values, and converting characters to NA as needed. Then, I converted `land_cover` to a numeric column, which made it easier to check the values that were not between 0-100%. There were two values for `land_cover` that were less than zero. I coerced -298 to NA since the other values available did not properly add up to 100. For -100, the value of water cover was zero, and snow cover was NA. In this case I felt like an accident was clearly made in adding a negative sign, so I changed land cover to be 100, and snow cover to be zero.

```{r}
# check data type and NA values
# class(snowsurvey_clean$land_cover)
# unique(snowsurvey_clean$land_cover)

snowsurvey_clean <- snowsurvey_clean %>% 
  # convert symbols into NAs
  mutate(land_cover = ifelse(land_cover %in% c(".", "-", "n/a", "unk"), 
                             NA, land_cover)) %>% 
  
  # correct data type
  mutate(land_cover = as.numeric(land_cover))

# check percentages
# snowsurvey_clean %>% filter(land_cover > 100 | land_cover < 0) %>% 
# head(10)

# change -298 to NA
snowsurvey_clean <- snowsurvey_clean %>% 
  mutate(land_cover = ifelse(land_cover == -298, NA, land_cover))

# manually update row for -100 land cover
snowsurvey_clean$snow_cover[223] <- 0
snowsurvey_clean$land_cover[223] <- 100
```

## Infer Missing Values

#### Managing NA Values

To start, I cleaned the `total_cover` column in the same manner as all the previous column. For some strange reason, one value of total cover was a string of characters and numbers so it needed to be added to the list of NAs. I decided to remove columns where all three variables (land cover, snow cover, and water cover) were NA as these did not tell us much about the conditions that day. Finally, there was a single total_cover value above 100 which I decided to remove. While there were multiple values under 100, it felt excessive to remove them since there were far more entries that fit this description. Additionally, many of the columns added up correctly, just not to 100.

```{r}
snowsurvey_clean <- snowsurvey_clean %>% 
  
  # remove recognized NAs
  mutate(total_cover = ifelse(total_cover %in% c(".", "-", "n/a", "unk"), NA, total_cover)) %>% 
  
  # remove strange string by removing anything that contains "row"
  mutate(total_cover = ifelse(str_detect(total_cover, "row"), NA, total_cover)) %>% 
  
  # remove columns where all values are NA
  filter(!is.na(snow_cover) | !is.na(water_cover) | !is.na(land_cover)) %>% 
  
  # convert column to numeric
  mutate(total_cover = as.numeric(total_cover)) %>% 
  
  # remove column above 100
  filter(total_cover <= 100)

```

**Missing Values**

I only wanted to infer values if a single one was missing. To do this, I used an `is.na()` search within the `ifelse()` function. This method allows me to only predict values where the one column is missing, meaning they could be more accurately estimated. I did this for each of the variables, creating new columns to preserve the original data. Once the cover variables were inferred, I re-calculated the total_cover for each entry.

```{r}
snowsurvey_clean <- snowsurvey_clean %>% 

  # estimate snow cover values
  mutate(snow_cover_est = ifelse(is.na(snow_cover), 
                                  total_cover - (water_cover + land_cover),
                                  snow_cover),
         
         # estimate water cover values
         water_cover_est = ifelse(is.na(water_cover),
                                   total_cover - (snow_cover + land_cover),
                                   water_cover),
         
         # estimate land cover values
         land_cover_est = ifelse(is.na(land_cover),
                                  total_cover - (snow_cover + land_cover),
                                  land_cover)) %>% 
  
  # calculate new total using estimated values
  mutate(new_total = snow_cover_est + water_cover_est + land_cover_est)
```

## Write CSV

```{r}
write_csv(snowsurvey_clean, here("data", "processed", "all_cover_fixed_BRIANA.csv"))
```
